{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import nfl_data_py as nfl\n",
    "import pandas as pd\n",
    "from functions import import_schedule_data, import_weekly_performance_data, load_and_process_kicker_data, load_and_process_defense_data\n",
    "from functions import scrape_adp_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n",
      "Downcasting floats.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "# Weekly performance data\n",
    "# Define the years for which you want to import and filter data\n",
    "years = [2019, 2020, 2021]\n",
    "\n",
    "# Call the functions to get the filtered data\n",
    "weekly_performance_2019 = import_weekly_performance_data([2019])\n",
    "weekly_performance_2020 = import_weekly_performance_data([2020])\n",
    "weekly_performance_2021 = import_weekly_performance_data([2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  kicker = pd.read_html(str(table))[0]\n",
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  kicker = pd.read_html(str(table))[0]\n",
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  kicker = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "# Kicker data\n",
    "# Get Roster data to enrich with Kicker data\n",
    "roster_2019 = nfl.import_seasonal_rosters([2019])\n",
    "roster_2020 = nfl.import_seasonal_rosters([2020])\n",
    "roster_2021 = nfl.import_seasonal_rosters([2021])\n",
    "\n",
    "# Load and process Kicker data for each year\n",
    "full_kicker_2019 = load_and_process_kicker_data(2019, roster_2019)\n",
    "full_kicker_2020 = load_and_process_kicker_data(2020, roster_2020)\n",
    "full_kicker_2021 = load_and_process_kicker_data(2021, roster_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:63: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  defense = pd.read_html(str(table))[0]\n",
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:63: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  defense = pd.read_html(str(table))[0]\n",
      "c:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\functions.py:63: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  defense = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "# Defense data\n",
    "# Load and process Defense data for each year\n",
    "full_defense_2019 = load_and_process_defense_data(2019)\n",
    "full_defense_2020 = load_and_process_defense_data(2020)\n",
    "full_defense_2021 = load_and_process_defense_data(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years for which you have data\n",
    "years = [2019, 2020, 2021]\n",
    "\n",
    "# Create dictionaries to store the combined data for each year\n",
    "k_dst_combined_dict = {}\n",
    "complete_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    long_kicker = globals()[f'full_kicker_{year}']\n",
    "    long_defense = globals()[f'full_defense_{year}']\n",
    "    weekly_performance = globals()[f'weekly_performance_{year}']\n",
    "\n",
    "    # Combine kicker and defense DataFrames\n",
    "    k_dst_year = pd.concat([long_kicker, long_defense], axis=0, ignore_index=True, sort=False)\n",
    "    k_dst_year = k_dst_year.rename(columns={'Team': 'recent_team', 'Pos': 'position', 'Points': 'fantasy_points_ppr', 'Week': 'week', 'Player': 'player_display_name'})\n",
    "\n",
    "    # Convert data types and handle missing values\n",
    "    k_dst_year['week'] = k_dst_year['week'].astype('int32')\n",
    "    k_dst_year['fantasy_points_ppr'] = pd.to_numeric(k_dst_year['fantasy_points_ppr'], errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "    # Store combined DataFrame in a dictionary\n",
    "    k_dst_combined_dict[f'long_combined_{year}'] = k_dst_year\n",
    "\n",
    "    # Concatenate with the complete DataFrame for the specific year\n",
    "    complete_year = pd.concat([weekly_performance, k_dst_year], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "    # Replace team names in the 'recent_team' column\n",
    "    complete_year['recent_team'] = complete_year['recent_team'].replace({'JAC': 'JAX', 'LA': 'LAR', 'OAK': 'LV'})\n",
    "\n",
    "    # Check if \"position group\" column is empty\n",
    "    mask = complete_year['position_group'].isnull()\n",
    "\n",
    "    # Copy value from \"position\" column to \"position group\" column where it is empty\n",
    "    complete_year.loc[mask, 'position_group'] = complete_year.loc[mask, 'position']\n",
    "\n",
    "    # Only keep the columns that are needed\n",
    "    complete_year = complete_year[['player_id', 'player_display_name', 'position_group', 'recent_team', 'season', 'week', 'fantasy_points_ppr']]\n",
    "    \n",
    "    # Store complete DataFrame in a dictionary\n",
    "    complete_dict[f'player_fantasy_data_{year}'] = complete_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant positions\n",
    "relevant_positions = ['QB', 'RB', 'WR', 'TE', 'K', 'DST']\n",
    "\n",
    "filtered_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    complete_data = complete_dict[f'player_fantasy_data_{year}']\n",
    "    filtered_data = complete_data[complete_data['position_group'].isin(relevant_positions)]\n",
    "    filtered_dict[f'player_fantasy_data_{year}'] = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store average and variance data for each year\n",
    "fantasy_points_dict = {}\n",
    "\n",
    "# Calculate average fantasy points and variance for each year\n",
    "for year in years:\n",
    "    filtered_data = filtered_dict[f'player_fantasy_data_{year}']\n",
    "    \n",
    "    # Calculate average fantasy points and variance for each player in the current year\n",
    "    player_stats = filtered_data.groupby('player_id')['fantasy_points_ppr'].agg(['mean', 'var']).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    player_stats.columns = ['player_id', f'average_points_{year}', f'variance_points_{year}']\n",
    "    \n",
    "    # Append the calculated stats for the current year to the dictionary\n",
    "    fantasy_points_dict[year] = player_stats[['player_id', f'average_points_{year}', f'variance_points_{year}']]\n",
    "    \n",
    "# Merge the calculated stats with the existing complete_year DataFrame\n",
    "fantasy_points = complete_year.copy()\n",
    "\n",
    "for year in years:\n",
    "    # Merge with the stats for the current year\n",
    "    fantasy_points = pd.merge(fantasy_points, fantasy_points_dict[year], on='player_id', how='left')\n",
    "\n",
    "# Filter out positions that are not in relevant_positions\n",
    "fantasy_points = fantasy_points[fantasy_points['position_group'].isin(relevant_positions)]\n",
    "\n",
    "# Drop columns for 2021\n",
    "fantasy_points = fantasy_points.drop(columns=['average_points_2021', 'variance_points_2021'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store average and variance data for each year\n",
    "fantasy_points_dict = {}\n",
    "\n",
    "# Calculate average fantasy points and variance for each year\n",
    "for year in years:\n",
    "    filtered_data = filtered_dict[f'player_fantasy_data_{year}']\n",
    "    \n",
    "    # Calculate average fantasy points and variance for each player in the current year\n",
    "    player_stats = filtered_data.groupby('player_id')['fantasy_points_ppr'].agg(['mean', 'var']).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    player_stats.columns = ['player_id', f'average_points_{year}', f'variance_points_{year}']\n",
    "    \n",
    "    # Append the calculated stats for the current year to the dictionary\n",
    "    fantasy_points_dict[year] = player_stats[['player_id', f'average_points_{year}', f'variance_points_{year}']]\n",
    "    \n",
    "# Merge the calculated stats with the existing complete_year DataFrame\n",
    "fantasy_points = complete_year.copy()\n",
    "\n",
    "for year in years:\n",
    "    # Merge with the stats for the current year\n",
    "    fantasy_points = pd.merge(fantasy_points, fantasy_points_dict[year], on='player_id', how='left')\n",
    "\n",
    "# Filter out positions that are not in relevant_positions\n",
    "fantasy_points = fantasy_points[fantasy_points['position_group'].isin(relevant_positions)]\n",
    "\n",
    "# Drop columns for 2021\n",
    "fantasy_points = fantasy_points.drop(columns=['average_points_2021', 'variance_points_2021'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule data\n",
    "# Define the years for which you want to import and filter data\n",
    "years = [2019, 2020, 2021]\n",
    "\n",
    "# Call the functions to get the filtered data\n",
    "schedule_2019 = import_schedule_data([2019])\n",
    "schedule_2020 = import_schedule_data([2020])\n",
    "schedule_2021 = import_schedule_data([2021])\n",
    "\n",
    "# Calculating defensive fantasy points allowed\n",
    "# Create a dictionary to store average fantasy points allowed data for each year\n",
    "avg_fantasy_points_allowed_dict = {}\n",
    "\n",
    "# Calculate average fantasy points allowed for each team and position group for each year\n",
    "for year in years:\n",
    "    # Retrieve the schedule dataframe for the current year\n",
    "    schedule = globals()[f'schedule_{year}']\n",
    "\n",
    "    # Replace team abbreviations in the 'home_team' and 'away_team' columns\n",
    "    schedule['home_team'] = schedule['home_team'].replace({'JAC': 'JAX', 'LA': 'LAR', 'OAK': 'LV'})\n",
    "    schedule['away_team'] = schedule['away_team'].replace({'JAC': 'JAX', 'LA': 'LAR', 'OAK': 'LV'})\n",
    "\n",
    "    # Retrieve the player_fantasy_data dataframe for the current year\n",
    "    player_fantasy_data = fantasy_points\n",
    "\n",
    "    # Merge with the schedule dataframe for home teams\n",
    "    home_games = player_fantasy_data.merge(schedule, left_on=['recent_team', 'week'], right_on=['home_team', 'week'], how='left')\n",
    "\n",
    "    # Merge with the schedule dataframe for away teams\n",
    "    away_games = player_fantasy_data.merge(schedule, left_on=['recent_team', 'week'], right_on=['away_team', 'week'], how='left')\n",
    "\n",
    "    # Create a copy of the original dataframe\n",
    "    fantasy_data_copy = player_fantasy_data.copy()\n",
    "\n",
    "    # Reset index for all dataframes\n",
    "    home_games = home_games.reset_index(drop=True)\n",
    "    away_games = away_games.reset_index(drop=True)\n",
    "    fantasy_data_copy = fantasy_data_copy.reset_index(drop=True)\n",
    "\n",
    "    # Update the opponent column based on home and away teams\n",
    "    fantasy_data_copy.loc[:, 'opponent'] = home_games['away_team']\n",
    "    nan_rows = fantasy_data_copy['opponent'].isna()\n",
    "    fantasy_data_copy.loc[nan_rows, 'opponent'] = away_games.loc[nan_rows, 'home_team']\n",
    "\n",
    "    # Calculate average fantasy points allowed for each team and position group\n",
    "    avg_fantasy_points_allowed = fantasy_data_copy.groupby(['opponent', 'position_group'])['fantasy_points_ppr'].mean().reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    avg_fantasy_points_allowed.columns = ['team', 'position_group', f'avg_fantasy_points_allowed_{year}']\n",
    "\n",
    "    # Store the calculated stats for the current year in the dictionary\n",
    "    avg_fantasy_points_allowed_dict[year] = avg_fantasy_points_allowed\n",
    "\n",
    "    # Filter out rows where 'opponent' is NaN in the fantasy_data_copy dataframe\n",
    "    fantasy_data_player = fantasy_data_copy.dropna(subset=['opponent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract home game information for the schedule\n",
    "home = schedule[['game_id', 'home_team', 'week']].copy()\n",
    "home['home_game'] = True\n",
    "\n",
    "# Extract away game information for the 2020 schedule\n",
    "away = schedule[['game_id', 'away_team', 'week']].copy()\n",
    "away['home_game'] = False\n",
    "\n",
    "# Rename columns for clarity in the home and away dataframes\n",
    "home.rename(columns={'home_team': 'recent_team'}, inplace=True)\n",
    "away.rename(columns={'away_team': 'recent_team'}, inplace=True)\n",
    "\n",
    "# Concatenate home and away dataframes to create a dataframe with all games\n",
    "all_games = pd.concat([home, away], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# Merge the fantasy_data_player dataframe with the all_games dataframe based on 'recent_team' and 'week'\n",
    "fantasy_data_player = fantasy_data_player.merge(all_games, on=['recent_team', 'week'], how='left')\n",
    "\n",
    "# Rename the 'team' column in avg_fantasy_points_allowed_dict[2020] to 'opponent'\n",
    "avg_fantasy_points_allowed_dict[2020].rename(columns={'team': 'opponent'}, inplace=True)\n",
    "\n",
    "# Merge the fantasy_data_player dataframe with the avg_fantasy_points_allowed_dict[2020] dataframe\n",
    "# based on 'opponent' and 'position_group'\n",
    "fantasy_data_player = fantasy_data_player.merge(avg_fantasy_points_allowed_dict[2020], on=['opponent', 'position_group'], how='left')\n",
    "\n",
    "# Rename the 'team' column in avg_fantasy_points_allowed_dict[2019] to 'opponent'\n",
    "avg_fantasy_points_allowed_dict[2019].rename(columns={'team': 'opponent'}, inplace=True)\n",
    "\n",
    "# Merge the fantasy_data_player dataframe with the avg_fantasy_points_allowed_dict[2019] dataframe\n",
    "# based on 'opponent' and 'position_group'\n",
    "fantasy_data_player = fantasy_data_player.merge(avg_fantasy_points_allowed_dict[2019], on=['opponent', 'position_group'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of columns you want\n",
    "column_order = ['player_id', 'player_display_name', 'position_group', 'recent_team', 'season', 'week', 'fantasy_points_ppr', 'opponent', 'game_id', 'home_game', 'avg_fantasy_points_allowed_2020', 'avg_fantasy_points_allowed_2019', 'average_points_2019', 'variance_points_2019', 'average_points_2020', 'variance_points_2020']\n",
    "\n",
    "# Reorder the columns in the DataFrame and uniform names\n",
    "fantasy_data_player = fantasy_data_player[column_order]\n",
    "fantasy_data_player['player_display_name'] = fantasy_data_player['player_display_name'].replace({'D.J. ': 'DJ '}, regex=True)\n",
    "\n",
    "# Impute missing values in average_points and variance_points with the mean of the respective column\n",
    "fantasy_data_player['average_points_2019'].fillna(fantasy_data_player['average_points_2019'].mean(), inplace=True)\n",
    "fantasy_data_player['variance_points_2019'].fillna(fantasy_data_player['variance_points_2019'].mean(), inplace=True)\n",
    "\n",
    "fantasy_data_player['average_points_2020'].fillna(fantasy_data_player['average_points_2020'].mean(), inplace=True)\n",
    "fantasy_data_player['variance_points_2020'].fillna(fantasy_data_player['variance_points_2020'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for the models\n",
    "features = ['avg_fantasy_points_allowed_2020', 'avg_fantasy_points_allowed_2019', 'average_points_2019', 'variance_points_2019', 'average_points_2020', 'variance_points_2020', 'home_game']\n",
    "target = 'fantasy_points_ppr'\n",
    "\n",
    "# Prepare train and test data\n",
    "X_train, X_test = fantasy_data_player[features], fantasy_data_player[features]\n",
    "y_train, y_test = fantasy_data_player[target], fantasy_data_player[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model\n",
      "Mean Absolute Error: 5.24301290512085\n",
      "Mean Squared Error: 45.38597106933594\n",
      "Root Mean Squared Error: 6.736911296844482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "mae = mean_absolute_error(y_test, prediction_lr)\n",
    "mse = mean_squared_error(y_test, prediction_lr)\n",
    "rmse = mean_squared_error(y_test, prediction_lr, squared=False)\n",
    "\n",
    "print(\"Linear Regression Model\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\\n\")\n",
    "\n",
    "# Add predictions to a copy of the dataframe\n",
    "fantasy_data_player_lr = fantasy_data_player.copy()\n",
    "fantasy_data_player_lr['predicted_fantasy_points'] = prediction_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Model\n",
      "Mean Absolute Error: 2.2429279798369897\n",
      "Mean Squared Error: 10.299243174651881\n",
      "Root Mean Squared Error: 3.2092433959816575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=17)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "mae = mean_absolute_error(y_test, prediction_rf)\n",
    "mse = mean_squared_error(y_test, prediction_rf)\n",
    "rmse = mean_squared_error(y_test, prediction_rf, squared=False)\n",
    "\n",
    "print(\"Random Forest Regressor Model\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\\n\")\n",
    "\n",
    "# Add predictions to a copy of the dataframe\n",
    "fantasy_data_player_rf = fantasy_data_player.copy()\n",
    "fantasy_data_player_rf['predicted_fantasy_points'] = prediction_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:312: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:314: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:345: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:336: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model\n",
      "Mean Absolute Error: 3.1939964294433594\n",
      "Mean Squared Error: 18.82990837097168\n",
      "Root Mean Squared Error: 4.339344024658203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:312: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:314: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:345: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\Users\\Lenny\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\data.py:336: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=17)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "mae = mean_absolute_error(y_test, prediction_xgb)\n",
    "mse = mean_squared_error(y_test, prediction_xgb)\n",
    "rmse = mean_squared_error(y_test, prediction_xgb, squared=False)\n",
    "\n",
    "print(\"XGBoost Model\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\\n\")\n",
    "\n",
    "# Add predictions to a copy of the dataframe\n",
    "fantasy_data_player_xgb = fantasy_data_player.copy()\n",
    "fantasy_data_player_xgb['predicted_fantasy_points'] = prediction_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as csv files for later import\n",
    "fantasy_data_player_rf.to_csv('fantasy_data_player_rf.csv', index=False)\n",
    "fantasy_data_player_xgb.to_csv('fantasy_data_player_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ADP data\n",
    "adp_data = scrape_adp_data(2021)\n",
    "\n",
    "# Add player to the adp_data dataframe\n",
    "adp_data = pd.merge(adp_data, fantasy_data_player[['player_display_name', 'player_id']], left_on='Player', right_on='player_display_name', how='left')\n",
    "\n",
    "# Clean up the adp_data dataframe\n",
    "adp_data = adp_data.drop(columns=['player_display_name'])\n",
    "\n",
    "# Drop duplicates based on 'player_id'\n",
    "adp_data = adp_data.drop_duplicates(subset='player_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average projected fantasy points for each player in 2021\n",
    "average_projections_2021 = fantasy_data_player_rf.groupby(['player_id', 'player_display_name', 'position_group'])['predicted_fantasy_points'].mean().reset_index()\n",
    "average_projections_2021 = average_projections_2021.sort_values('predicted_fantasy_points', ascending=False)\n",
    "\n",
    "# Sum of projected fantasy points for each player in 2021\n",
    "player_projections_2021 = fantasy_data_player_rf.groupby(['player_id', 'player_display_name', 'position_group'])['predicted_fantasy_points'].sum().reset_index()\n",
    "player_projections_2021 = player_projections_2021.sort_values('predicted_fantasy_points', ascending=False)\n",
    "\n",
    "# Merge with the adp_data dataframe\n",
    "adp_data = pd.merge(adp_data, player_projections_2021[['player_id', 'position_group', 'predicted_fantasy_points']], on=['player_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking based on projected fantasy points for each player in 2021\n",
    "# Sort players by position_group and predicted_fantasy_points\n",
    "position_ranks = adp_data\n",
    "position_ranks['AVG'] = position_ranks['AVG'].astype('float32')\n",
    "position_ranks = adp_data.sort_values(by=['position_group', 'predicted_fantasy_points'], ascending=[True, False])\n",
    "\n",
    "# Set the cutoff point for the VOR model\n",
    "cutoff_vor = 120\n",
    "\n",
    "# Select players with AVG <= adp_cutoff\n",
    "selected_players = position_ranks[position_ranks['AVG'] <= cutoff_vor]\n",
    "\n",
    "# Find the last selected player for each position\n",
    "replacement_players = selected_players.groupby('position_group').last()\n",
    "\n",
    "# Function to calculate replacement value for each player\n",
    "def calculate_vor(row):\n",
    "    if row['position_group'] in replacement_players.index:\n",
    "        return replacement_players.loc[row['position_group'], 'predicted_fantasy_points']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the replacement_value function to calculate 'replacement_value' for each player\n",
    "position_ranks['replacement_value'] = position_ranks.apply(calculate_vor, axis=1)\n",
    "\n",
    "# Calculate 'VOR' for each player\n",
    "position_ranks['vor'] = position_ranks['predicted_fantasy_points'] - position_ranks['replacement_value']\n",
    "\n",
    "# Sort players by 'VOR'\n",
    "ranking_players = position_ranks.sort_values('vor', ascending=False)\n",
    "\n",
    "# Create a new column 'rank' representing the player's rank based on VOR\n",
    "ranking_players['rank'] = ranking_players['vor'].rank(ascending=False, method='min')\n",
    "\n",
    "# Convert 'rank' to float\n",
    "ranking_players['rank'] = ranking_players['rank'].astype(float)\n",
    "\n",
    "# Merge the VOR rankings with your existing dataframe\n",
    "merged_adp_ranking = pd.merge(adp_data, ranking_players[['player_id', 'predicted_fantasy_points', 'position_group', 'replacement_value', 'vor', 'rank']], on='player_id')\n",
    "\n",
    "# Calculate the average rank based on 'rank' and 'AVG'\n",
    "merged_adp_ranking['average_rank'] = merged_adp_ranking[['rank', 'AVG']].mean(axis=1)\n",
    "\n",
    "# Rename columns and drop duplicate columns \n",
    "merged_adp_ranking = merged_adp_ranking.rename(columns={'predicted_fantasy_points_x': 'predicted_fantasy_points', 'AVG': 'adp_rank', 'position_group_x': 'position_group'})\n",
    "merged_adp_ranking = merged_adp_ranking.drop(columns=['predicted_fantasy_points_y', 'position_group_y'])\n",
    "\n",
    "# Sort the merged dataframe by 'rank'\n",
    "merged_adp_ranking = merged_adp_ranking.sort_values('rank', ascending=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "merged_adp_ranking.to_csv('merged_adp_ranks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a copy of the dataframe to avoid modifying the original data\n",
    "adp_and_vor_data = adp_data.copy()\n",
    "\n",
    "# Rank players based on ADP ranks\n",
    "adp_and_vor_data['adp_rank'] = adp_and_vor_data['AVG'].rank(ascending=True, method='min')\n",
    "\n",
    "# Set the cutoff point for the VOR model\n",
    "cutoff_vor = 120\n",
    "\n",
    "# Select players with AVG <= cutoff_vor\n",
    "selected_players_vor = adp_and_vor_data[adp_and_vor_data['AVG'] <= cutoff_vor]\n",
    "\n",
    "# Find the last selected player for each position\n",
    "replacement_players_vor = selected_players_vor.groupby('position_group').last()\n",
    "\n",
    "# Function to calculate replacement value for each player\n",
    "def calculate_vor(row):\n",
    "    if row['position_group'] in replacement_players_vor.index:\n",
    "        return replacement_players_vor.loc[row['position_group'], 'AVG']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the replacement_value function to calculate 'replacement_value' for each player\n",
    "adp_and_vor_data['replacement_value'] = adp_and_vor_data.apply(calculate_vor, axis=1)\n",
    "\n",
    "# Calculate 'vor' for each player\n",
    "adp_and_vor_data['vor'] = adp_and_vor_data['predicted_fantasy_points'] - adp_and_vor_data['replacement_value']\n",
    "\n",
    "# Generate final rankings based on the VOR-adjusted ranks\n",
    "# Sort players by 'vor'\n",
    "adp_and_vor_data = adp_and_vor_data.sort_values('vor', ascending=False)\n",
    "\n",
    "# Create a new column 'rank' representing the player's rank based on VOR\n",
    "adp_and_vor_data['rank'] = adp_and_vor_data['vor'].rank(ascending=False, method='min')\n",
    "\n",
    "# Convert 'rank' to float\n",
    "adp_and_vor_data['rank'] = adp_and_vor_data['rank'].astype(float)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "adp_and_vor_data.to_csv('adp_and_vor_ranks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "consensus_csv = r'C:\\Users\\Lenny\\seminar_paper_flath\\datadriven-fantasyfootball\\fantasy_football_data\\consensus_ranking.csv'\n",
    "consensus_data = pd.read_csv(consensus_csv, encoding='latin1')\n",
    "\n",
    "# Extract values inside brackets in the 'PLAYER NAME' column and create a new 'Team' column\n",
    "consensus_data['Team'] = consensus_data['PLAYER NAME'].str.extract(r'\\((.*?)\\)')\n",
    "\n",
    "# Remove brackets and their contents from 'PLAYER NAME' column\n",
    "consensus_data['PLAYER NAME'] = consensus_data['PLAYER NAME'].replace(r'\\(.*\\)', '', regex=True).str.strip()\n",
    "\n",
    "# Remove suffixes like 'Jr.', 'II', and 'III' from 'PLAYER NAME' column\n",
    "consensus_data['PLAYER NAME'] = consensus_data['PLAYER NAME'].replace(r'\\s(Jr\\.|II|III)$', '', regex=True).str.strip()\n",
    "consensus_data['PLAYER NAME'] = consensus_data['PLAYER NAME'].replace({'D.K. ': 'DK '}, regex=True).replace({'D.J. ': 'DJ '}, regex=True)\n",
    "\n",
    "# Fill empty cells with 'None'\n",
    "consensus_data['BYE WEEK'].fillna('None', inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "consensus_data.rename(columns={'RK': 'consensus_rank', 'PLAYER NAME': 'Player', 'BYE WEEK': 'Bye'}, inplace=True)\n",
    "\n",
    "# Merge consensus_data with fantasy_data_player to get player_id\n",
    "consensus_data = pd.merge(consensus_data, fantasy_data_player[['player_display_name', 'player_id']], left_on='Player', right_on='player_display_name', how='left')\n",
    "\n",
    "# Clean up the consensus_data DataFrame\n",
    "consensus_data = consensus_data.drop(columns=['player_display_name'])\n",
    "consensus_data = consensus_data.drop_duplicates(subset='player_id', keep='first')\n",
    "\n",
    "# Merge projections with consensus rankings\n",
    "consensus_data = pd.merge(consensus_data, player_projections_2021[['player_id', 'position_group', 'predicted_fantasy_points']], on=['player_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the consensus_data with adp_data based on player_id\n",
    "merged_data = pd.merge(consensus_data, adp_data[['player_id']], on='player_id', how='inner')\n",
    "\n",
    "# Select only the desired columns from the merged dataframe\n",
    "final_consensus_data = merged_data[['consensus_rank', 'Player', 'POS', 'Bye', 'Team', 'player_id', 'position_group', 'predicted_fantasy_points']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a copy of the dataframe to avoid modifying the original data\n",
    "consensus_and_vor_data = consensus_data.copy()\n",
    "\n",
    "# Rank players based on consensus ranks\n",
    "consensus_and_vor_data['consensus_rank'] = consensus_and_vor_data['consensus_rank'].astype(float)\n",
    "\n",
    "# Set the cutoff point for the VOR model\n",
    "cutoff_vor = 120\n",
    "\n",
    "# Select players with consensus_rank <= cutoff_vor\n",
    "selected_players_vor = consensus_and_vor_data[consensus_and_vor_data['consensus_rank'] <= cutoff_vor]\n",
    "\n",
    "# Find the last selected player for each position\n",
    "replacement_players_vor = selected_players_vor.groupby('position_group').last()\n",
    "\n",
    "# Function to calculate replacement value for each player\n",
    "def calculate_vor(row):\n",
    "    if row['position_group'] in replacement_players_vor.index:\n",
    "        return replacement_players_vor.loc[row['position_group'], 'consensus_rank']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the replacement_value function to calculate 'replacement_value' for each player\n",
    "consensus_and_vor_data['replacement_value'] = consensus_and_vor_data.apply(calculate_vor, axis=1)\n",
    "\n",
    "# Calculate 'vor' for each player\n",
    "consensus_and_vor_data['vor'] = consensus_and_vor_data['predicted_fantasy_points'] - consensus_and_vor_data['replacement_value']\n",
    "\n",
    "# Generate final rankings based on the vor-adjusted ranks\n",
    "# Sort players by 'vor'\n",
    "consensus_and_vor_data = consensus_and_vor_data.sort_values('vor', ascending=False)\n",
    "\n",
    "# Create a new column 'rank' representing the player's rank based on vor\n",
    "consensus_and_vor_data['rank'] = consensus_and_vor_data['vor'].rank(ascending=False, method='min')\n",
    "\n",
    "# Convert 'rank' to float\n",
    "consensus_and_vor_data['rank'] = consensus_and_vor_data['rank'].astype(float)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "consensus_and_vor_data.to_csv('consensus_ranks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "opportunity_cost = adp_data.copy()\n",
    "\n",
    "# Sort players based on projected points for the entire season\n",
    "opportunity_players = opportunity_cost.sort_values(by=['position_group', 'predicted_fantasy_points'], ascending=[True, False])\n",
    "\n",
    "# Calculate the opportunity cost for each player, representing the distance to the next best player at the same position\n",
    "opportunity_players['opportunity_cost'] = opportunity_players.groupby('position_group')['predicted_fantasy_points'].diff(-1).abs()\n",
    "\n",
    "# Fill NaN values with 0 (for the last player in each position)\n",
    "opportunity_players['opportunity_cost'].fillna(0, inplace=True)\n",
    "\n",
    "# Define weights for predicted_fantasy_points and opportunity_cost\n",
    "weights = {'predicted_fantasy_points': 0.5, 'opportunity_cost': 0.5}\n",
    "\n",
    "# Calculate the final score using the defined weights\n",
    "opportunity_players['final_score'] =  opportunity_players['predicted_fantasy_points'] * weights['predicted_fantasy_points'] + \\\n",
    "                                      opportunity_players['opportunity_cost'] * weights['opportunity_cost']\n",
    "\n",
    "# Sort players by the final score\n",
    "opportunity_players = opportunity_players.sort_values('final_score', ascending=False)\n",
    "\n",
    "# Assign ranks based on the final score\n",
    "opportunity_players['rank'] = opportunity_players['final_score'].rank(ascending=False, method='min')\n",
    "\n",
    "# Convert 'rank' to float\n",
    "opportunity_players['rank'] = opportunity_players['rank'].astype(float)\n",
    "\n",
    "# Merge the final rankings with your existing dataframe\n",
    "opportunity_cost_data = pd.merge(adp_data, opportunity_players[['player_id', 'predicted_fantasy_points', 'position_group', 'opportunity_cost', 'final_score', 'rank']], on='player_id')\n",
    "\n",
    "# Rename the columns\n",
    "opportunity_cost_data = opportunity_cost_data.rename(columns={\n",
    "    'predicted_fantasy_points_x': 'predicted_fantasy_points',\n",
    "    'position_group_x': 'position_group'\n",
    "})\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "opportunity_cost_data = opportunity_cost_data.drop(columns=[\n",
    "    'predicted_fantasy_points_y',\n",
    "    'position_group_y'\n",
    "])\n",
    "\n",
    "# Print the resulting dataframe\n",
    "opportunity_cost_data.to_csv('opportunity_cost_ranks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset (either adp_data or consensus_data)\n",
    "opportunity_cost_avg = average_projections_2021  # Replace with consensus_data if needed\n",
    "\n",
    "# Sort players based on projected points for the entire season\n",
    "opportunity_avg = opportunity_cost_avg.sort_values(by=['position_group', 'predicted_fantasy_points'], ascending=[True, False])\n",
    "\n",
    "# Calculate the opportunity cost for each player, representing the distance to the next best player at the same position\n",
    "opportunity_avg['opportunity_cost'] = opportunity_avg.groupby('position_group')['predicted_fantasy_points'].diff(-1).abs()\n",
    "\n",
    "# Fill NaN values with 0 (for the last player in each position)\n",
    "opportunity_avg['opportunity_cost'].fillna(0, inplace=True)\n",
    "\n",
    "# Define weights for predicted_fantasy_points and opportunity_cost\n",
    "weights = {'predicted_fantasy_points': 0.5, 'opportunity_cost': 0.5}\n",
    "\n",
    "# Calculate the final score using the defined weights\n",
    "opportunity_avg['final_score'] = opportunity_avg['predicted_fantasy_points'] * weights['predicted_fantasy_points'] + \\\n",
    "                                 opportunity_avg['opportunity_cost'] * weights['opportunity_cost']\n",
    "\n",
    "# Sort players by the final score\n",
    "players = opportunity_avg.sort_values('final_score', ascending=False)\n",
    "\n",
    "# Assign ranks based on the final score\n",
    "players['rank'] = players['final_score'].rank(ascending=False, method='min')\n",
    "\n",
    "# Convert 'rank' to float\n",
    "players['rank'] = players['rank'].astype(float)\n",
    "\n",
    "# Merge the final rankings with your existing dataframe\n",
    "opportunity_cost_avg_data = pd.merge(adp_data, players[['player_id', 'predicted_fantasy_points', 'position_group', 'opportunity_cost', 'final_score', 'rank']], on='player_id')\n",
    "\n",
    "# Rename the columns\n",
    "opportunity_cost_avg_data = opportunity_cost_avg_data.rename(columns={\n",
    "    'predicted_fantasy_points_x': 'predicted_fantasy_points',\n",
    "    'position_group_x': 'position_group'\n",
    "})\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "opportunity_cost_avg_data = opportunity_cost_avg_data.drop(columns=[\n",
    "    'predicted_fantasy_points_y',\n",
    "    'position_group_y'\n",
    "])\n",
    "\n",
    "# Print the resulting dataframe\n",
    "opportunity_cost_avg_data.to_csv('opportunity_cost_avg_ranks.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
